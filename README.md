# KukaReachRL (Spring 2025 Project)

This project implements reinforcement learning (SAC, PPO, TD3) for a 7-DoF KUKA iiwa reach task using the PyBullet simulator. The agent learns to move the robot's end-effector to a random 3D target position.

---

## ğŸ“ Structure


---

## ğŸ§  Algorithms

- âœ… **PID baseline**  
- âœ… **SAC** (vanilla, vectorized)  
- âœ… **PPO** (large-batch, on-policy)  
- âœ… **TD3**  
- âœ… **Optuna-SAC** (hyperparameter tuning)

---

## ğŸ§ª Evaluation

- **Success threshold**: 5â€¯cm  
- **Metrics**:
  - Final distance to target (lower is better)
  - Success rate (episodes with distance < 0.05â€¯m)
  - Episode length (steps)
  - FPS (frames per second)
- **Saliency analysis**: visualized input importance for Optuna-SAC

---

## ğŸ“· Media

See `artifacts/` for:
- ğŸ“Š GIFs of agent performance (front/back/left/top)
- ğŸ“ˆ Training reward logs (`TensorBoard` format)
- ğŸ§  Saliency barplots

---

## âš™ï¸ Training Configs

YAML files in `configs/` define:
- Physics parameters (gravity, time step)
- Reward shaping
- Curriculum thresholds
- Action discretization

---

## ğŸš€ Run in Colab

The project was trained on **Google Colab Pro** with:
- GPU: NVIDIA L4 (23â€¯GB)
- CUDA: 12.5
- PyTorch: 2.6.0

To reproduce, upload notebook and configs to Colab and run all cells.

---


